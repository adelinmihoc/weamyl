{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pjl3-loUfDyq"
      },
      "source": [
        "# CONV_LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnILp09NfUem"
      },
      "source": [
        "# Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4tzGTDlle77f"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install keras-self-attention\n",
        "!pip install celluloid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9uRW0K3DfX0h"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from glob import glob\n",
        "import cv2\n",
        "import xarray as xr\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import os.path\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from joblib import Parallel, delayed\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "import io\n",
        "import imageio\n",
        "from IPython.display import Image, display\n",
        "from ipywidgets import widgets, Layout, HBox\n",
        "from celluloid import Camera\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1f76p2Jzfa-g"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from keras import backend as K\n",
        "from keras.callbacks import CSVLogger, ModelCheckpoint\n",
        "from keras_self_attention import SeqSelfAttention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "roVVOWFNfgM1"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "tf.get_logger().setLevel(logging.ERROR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9x6ujCclfcsE",
        "outputId": "a43208e3-c65c-420b-e8b7-4c43a9d7776d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2WMPCKkfpxp"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UkE-thKgfpFA"
      },
      "outputs": [],
      "source": [
        "def get_seqed(data, seq_len):\n",
        "        stacked = np.stack(data)\n",
        "        seqed_data = []\n",
        "        for i in range(stacked.shape[0]-seq_len):\n",
        "            seqed_data.append(stacked[i:i+seq_len])\n",
        "        return np.stack(seqed_data)\n",
        "\n",
        "def get_data_for_conv_lstm(dataset):\n",
        "    # Split into train and validation sets using indexing to optimize memory.\n",
        "    indexes = np.arange(dataset.shape[0])\n",
        "    np.random.shuffle(indexes)\n",
        "    train_val_index = indexes[: int(0.8 * dataset.shape[0])]\n",
        "    test_index = indexes[int(0.8 * dataset.shape[0]) :]\n",
        "    train_val_dataset = dataset[train_val_index]\n",
        "    test_dataset = dataset[test_index]\n",
        "\n",
        "    train_val_index = np.arange(train_val_dataset.shape[0])\n",
        "    train_index = train_val_index[: int(0.9 * train_val_dataset.shape[0])]\n",
        "    val_index = train_val_index[int(0.9 * train_val_dataset.shape[0]):]\n",
        "    train_dataset = train_val_dataset[train_index]\n",
        "    val_dataset = train_val_dataset[val_index]\n",
        "\n",
        "    # Normalize the data to the 0-1 range.\n",
        "    train_dataset[train_dataset < 0] = 0\n",
        "    train_dataset[train_dataset > 255] = 255\n",
        "    val_dataset[val_dataset < 0] = 0\n",
        "    val_dataset[val_dataset > 255] = 255\n",
        "    test_dataset[test_dataset < 0] = 0\n",
        "    test_dataset[test_dataset > 255] = 255\n",
        "\n",
        "    min_train = np.min(train_dataset)\n",
        "    max_train = np.max(train_dataset)\n",
        "\n",
        "    print(\"Min train: {}, Max train: {}\".format(min_train, max_train))\n",
        "\n",
        "    train_dataset = train_dataset\n",
        "    val_dataset = val_dataset\n",
        "    test_dataset = test_dataset\n",
        "\n",
        "    def create_shifted_frames(data):\n",
        "      x = data[:, 0 : data.shape[1] - 1, :, :]\n",
        "      y = data[:, 1: data.shape[1], :, :]\n",
        "      return x, y\n",
        "\n",
        "    x_train, y_train = create_shifted_frames(train_dataset)\n",
        "    x_val, y_val = create_shifted_frames(val_dataset)\n",
        "    x_test, y_test = create_shifted_frames(test_dataset)\n",
        "\n",
        "    print(\"Training Dataset Shapes: \" + str(x_train.shape) + \", \" + str(y_train.shape))\n",
        "    print(\"Validation Dataset Shapes: \" + str(x_val.shape) + \", \" + str(y_val.shape))\n",
        "\n",
        "    return x_train, y_train, x_val, y_val, x_test, y_test, train_dataset, val_dataset, test_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtFJgMSefwMO",
        "outputId": "cd339790-fabf-447a-a656-c44668c9df84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Min train: 0.0, Max train: 255.0\n",
            "Training Dataset Shapes: (2057, 8, 120, 160, 3), (2057, 8, 120, 160, 3)\n",
            "Validation Dataset Shapes: (229, 8, 120, 160, 3), (229, 8, 120, 160, 3)\n"
          ]
        }
      ],
      "source": [
        "# convections = np.load('/content/drive/MyDrive/Licenta/np_data/np_data.npy')\n",
        "# convections = np.float32(convections)\n",
        "# convections = get_seqed(convections, 9)\n",
        "x_train, y_train, x_val, y_val, x_test, y_test, train_dataset, val_dataset, test_dataset = get_data_for_conv_lstm(np.load('/content/drive/MyDrive/Licenta/np_data/np_data_seq_9_float32.npy'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZwiDtU7gb6B"
      },
      "source": [
        "# Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ViH_R64XgdHO"
      },
      "outputs": [],
      "source": [
        "loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
        "mse_metric = keras.metrics.MeanSquaredError(name=\"mse\")\n",
        "mae_metric = keras.metrics.MeanAbsoluteError(name=\"mae\")\n",
        "\n",
        "beta = 0.01\n",
        "delta = 1.35\n",
        "\n",
        "class CustomModel(keras.Model):\n",
        "  def test_step(self, data):\n",
        "    x, y = data\n",
        "    y_pred = self(x, training=False)\n",
        "    self.compiled_loss(y[:, -1, :, :, :], y_pred[:, -1, :, :, :], regularization_losses=self.losses)\n",
        "    self.compiled_metrics.update_state(y, y_pred)\n",
        "    return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "  def train_step(self, data):\n",
        "    x, y = data\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "      y_pred = self(x, training=True)\n",
        "      # loss = tf.keras.losses.Huber(delta=delta)(y,y_pred)\n",
        "      loss = keras.losses.mean_squared_error(y, y_pred)\n",
        "      # keras.losses.mean_absolute_error(y, y_pred)\n",
        "      # loss = tf.nn.l2_loss(tf.subtract(y_pred, y))\n",
        "\n",
        "    trainable_vars = self.trainable_variables\n",
        "    gradients = tape.gradient(loss, trainable_vars)\n",
        "\n",
        "    self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "\n",
        "    loss_tracker.update_state(loss)\n",
        "    mse_metric.update_state(y, y_pred)\n",
        "    mae_metric.update_state(y, y_pred)\n",
        "\n",
        "    return {\"loss\": loss_tracker.result(), \"mse\": mse_metric.result(),  \"mae\": mae_metric.result()}\n",
        "\n",
        "  # property\n",
        "  # def metrics(self):\n",
        "  #   return [loss_tracker, mse_metric, mae_metric]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hAr8hzM9hfLM"
      },
      "outputs": [],
      "source": [
        "def build_conv_lstm(input_shape):\n",
        "    def input_layer():\n",
        "      return layers.Input(shape=(None, *input_shape[2:]), name=\"conv_lstm_input\")\n",
        "    \n",
        "    def convLSTM2D_block(filters: int, kernel_size, padding, strides, return_sequences, activation, normalized, layer_number):\n",
        "      model = keras.Sequential(name=\"convLSTM2D_{}_block_{}\".format(filters, layer_number))\n",
        "      model.add(layers.ConvLSTM2D(\n",
        "          filters=filters,\n",
        "          kernel_size=kernel_size,\n",
        "          padding=padding,\n",
        "          strides=strides, \n",
        "          return_sequences=return_sequences,\n",
        "          activation=activation,\n",
        "          activity_regularizer='l1'\n",
        "          ))\n",
        "      if normalized:\n",
        "        model.add(layers.BatchNormalization())\n",
        "      \n",
        "      return model\n",
        "    \n",
        "    def timeDistributed_block(filters, kernel_size, padding, strides, activation, normalized, layer_number):\n",
        "      model = keras.Sequential(name=\"timeDistributed_{}_block_{}\".format(filters, layer_number))\n",
        "      model.add(layers.TimeDistributed(\n",
        "          layers.Conv2DTranspose(\n",
        "            filters=filters,\n",
        "            kernel_size=kernel_size,\n",
        "            padding=padding,\n",
        "            strides=strides,\n",
        "            activation=activation\n",
        "      )))\n",
        "      if normalized:\n",
        "          model.add(layers.BatchNormalization())\n",
        "      \n",
        "      return model\n",
        "\n",
        "    def conv3D_block(filters, kernel_size, activation, padding, layer_number):\n",
        "      model = keras.Sequential(name=\"conv3D_{}_block_{}\".format(filters, layer_number))\n",
        "      model.add(layers.Conv3D(\n",
        "          filters=filters,\n",
        "          kernel_size=kernel_size,\n",
        "          activation=activation,\n",
        "          padding=padding\n",
        "      ))\n",
        "\n",
        "      return model\n",
        "\n",
        "    def create_model():\n",
        "      inputs = input_layer()\n",
        "\n",
        "      x = inputs\n",
        "      x = convLSTM2D_block(filters=128, kernel_size=(5,5), padding=\"same\", strides=(1,1), return_sequences=True, activation='relu', normalized=True, layer_number=1)(x)\n",
        "      x = convLSTM2D_block(filters=256, kernel_size=(5,5), padding=\"same\", strides=(2,2), return_sequences=True, activation='relu', normalized=True, layer_number=2)(x)\n",
        "      x = convLSTM2D_block(filters=256, kernel_size=(3,3), padding=\"same\", strides=(1,1), return_sequences=True, activation='relu', normalized=True, layer_number=3)(x)\n",
        "      x = convLSTM2D_block(filters=512, kernel_size=(1,1), padding=\"same\", strides=(2,2), return_sequences=True, activation='relu', normalized=True, layer_number=4)(x)\n",
        "      x = timeDistributed_block(filters=256, kernel_size=(2,2), padding=\"same\", strides=(2,2), activation='relu', normalized=True, layer_number=5)(x)\n",
        "      x = timeDistributed_block(filters=128, kernel_size=(2,2), padding=\"same\", strides=(2,2), activation='relu', normalized=False, layer_number=6)(x)\n",
        "      x = conv3D_block(filters=3, kernel_size=(1,1,1), padding=\"same\",activation='relu', layer_number=7)(x)\n",
        "\n",
        "      outputs = layers.Add(name=\"conv_lstm_output\")([inputs, x])\n",
        "\n",
        "      return CustomModel(inputs=inputs, outputs=outputs, name=\"conv_lstm\")\n",
        "    \n",
        "    return create_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WCpfdmEKhxbW"
      },
      "outputs": [],
      "source": [
        "model = build_conv_lstm(x_train.shape)\n",
        "# model = tf.keras.models.load_model('/content/drive/MyDrive/Licenta/models/ultimate_weamyl-lstm_best_model_20220320193323.hdf5', custom_objects={'CustomModel': CustomModel})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZgRwWQPjNml"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QGOtKVkwh8S1"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001))\n",
        "\n",
        "now = int(datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\"))\n",
        "# reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=5, min_delta=0.1, verbose=1)\n",
        "csv_logger = CSVLogger('/content/drive/MyDrive/Licenta/logs/weamyl-lstm_log_{}.csv'.format(now), append=True, separator=',')\n",
        "checkpoint = ModelCheckpoint('/content/drive/MyDrive/Licenta/models/weamyl-lstm_best_model_{}.hdf5'.format(now), monitor='loss', verbose=1, save_best_only=True, mode='auto', period=1)\n",
        "epochs = 200\n",
        "batch_size = 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbfOZ5zo7zvd",
        "outputId": "fd202f0d-aef3-4ad1-fa7c-f4ddba3b979a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "2057/2057 [==============================] - ETA: 0s - loss: 95.5197 - mse: 95.5197 - mae: 4.4380\n",
            "Epoch 1: loss improved from inf to 95.04255, saving model to /content/drive/MyDrive/Licenta/models/weamyl-lstm_best_model_20220320193323.hdf5\n",
            "2057/2057 [==============================] - 1808s 870ms/step - loss: 95.5195 - mse: 95.5195 - mae: 4.4380\n",
            "Epoch 2/200\n",
            "2057/2057 [==============================] - ETA: 0s - loss: 93.9891 - mse: 94.4294 - mae: 4.4093\n",
            "Epoch 2: loss improved from 95.04255 to 93.98914, saving model to /content/drive/MyDrive/Licenta/models/weamyl-lstm_best_model_20220320193323.hdf5\n",
            "2057/2057 [==============================] - 1789s 870ms/step - loss: 93.9891 - mse: 94.4292 - mae: 4.4093\n",
            "Epoch 3/200\n",
            "2057/2057 [==============================] - ETA: 0s - loss: 93.0248 - mse: 93.4334 - mae: 4.3874\n",
            "Epoch 3: loss improved from 93.98914 to 93.02477, saving model to /content/drive/MyDrive/Licenta/models/weamyl-lstm_best_model_20220320193323.hdf5\n",
            "2057/2057 [==============================] - 1788s 869ms/step - loss: 93.0248 - mse: 93.4332 - mae: 4.3874\n",
            "Epoch 4/200\n",
            "2057/2057 [==============================] - ETA: 0s - loss: 92.1131 - mse: 92.4322 - mae: 4.3653\n",
            "Epoch 4: loss improved from 93.02477 to 92.11308, saving model to /content/drive/MyDrive/Licenta/models/weamyl-lstm_best_model_20220320193323.hdf5\n",
            "2057/2057 [==============================] - 1788s 869ms/step - loss: 92.1131 - mse: 92.4321 - mae: 4.3652\n",
            "Epoch 5/200\n",
            "2057/2057 [==============================] - ETA: 0s - loss: 91.2858 - mse: 91.7173 - mae: 4.3508\n",
            "Epoch 5: loss improved from 92.11308 to 91.28577, saving model to /content/drive/MyDrive/Licenta/models/weamyl-lstm_best_model_20220320193323.hdf5\n",
            "2057/2057 [==============================] - 1788s 869ms/step - loss: 91.2858 - mse: 91.7171 - mae: 4.3508\n",
            "Epoch 6/200\n",
            "2057/2057 [==============================] - ETA: 0s - loss: 90.5093 - mse: 90.8809 - mae: 4.3321\n",
            "Epoch 6: loss improved from 91.28577 to 90.50927, saving model to /content/drive/MyDrive/Licenta/models/weamyl-lstm_best_model_20220320193323.hdf5\n",
            "2057/2057 [==============================] - 1788s 869ms/step - loss: 90.5093 - mse: 90.8807 - mae: 4.3321\n",
            "Epoch 7/200\n",
            "2057/2057 [==============================] - ETA: 0s - loss: 89.8022 - mse: 90.1912 - mae: 4.3182\n",
            "Epoch 7: loss improved from 90.50927 to 89.80219, saving model to /content/drive/MyDrive/Licenta/models/weamyl-lstm_best_model_20220320193323.hdf5\n",
            "2057/2057 [==============================] - 1788s 869ms/step - loss: 89.8022 - mse: 90.1910 - mae: 4.3182\n",
            "Epoch 8/200\n",
            "2057/2057 [==============================] - ETA: 0s - loss: 89.1511 - mse: 89.4609 - mae: 4.3011\n",
            "Epoch 8: loss improved from 89.80219 to 89.15114, saving model to /content/drive/MyDrive/Licenta/models/weamyl-lstm_best_model_20220320193323.hdf5\n",
            "2057/2057 [==============================] - 1788s 869ms/step - loss: 89.1511 - mse: 89.4607 - mae: 4.3011\n",
            "Epoch 9/200\n",
            "2057/2057 [==============================] - ETA: 0s - loss: 88.5505 - mse: 88.8790 - mae: 4.2885\n",
            "Epoch 9: loss improved from 89.15114 to 88.55051, saving model to /content/drive/MyDrive/Licenta/models/weamyl-lstm_best_model_20220320193323.hdf5\n",
            "2057/2057 [==============================] - 1788s 869ms/step - loss: 88.5505 - mse: 88.8788 - mae: 4.2885\n",
            "Epoch 10/200\n",
            "2057/2057 [==============================] - ETA: 0s - loss: 87.9903 - mse: 88.2672 - mae: 4.2738\n",
            "Epoch 10: loss improved from 88.55051 to 87.99033, saving model to /content/drive/MyDrive/Licenta/models/weamyl-lstm_best_model_20220320193323.hdf5\n",
            "2057/2057 [==============================] - 1788s 869ms/step - loss: 87.9903 - mse: 88.2670 - mae: 4.2738\n",
            "Epoch 11/200\n",
            "2057/2057 [==============================] - ETA: 0s - loss: 87.4798 - mse: 87.7083 - mae: 4.2610\n",
            "Epoch 11: loss improved from 87.99033 to 87.47982, saving model to /content/drive/MyDrive/Licenta/models/weamyl-lstm_best_model_20220320193323.hdf5\n",
            "2057/2057 [==============================] - 1788s 869ms/step - loss: 87.4798 - mse: 87.7082 - mae: 4.2610\n",
            "Epoch 12/200\n",
            "2057/2057 [==============================] - ETA: 0s - loss: 87.0005 - mse: 87.2564 - mae: 4.2507\n",
            "Epoch 12: loss improved from 87.47982 to 87.00047, saving model to /content/drive/MyDrive/Licenta/models/weamyl-lstm_best_model_20220320193323.hdf5\n",
            "2057/2057 [==============================] - 1788s 869ms/step - loss: 87.0005 - mse: 87.2562 - mae: 4.2507\n",
            "Epoch 13/200\n",
            "2057/2057 [==============================] - ETA: 0s - loss: 86.5540 - mse: 86.7742 - mae: 4.2389\n",
            "Epoch 13: loss improved from 87.00047 to 86.55401, saving model to /content/drive/MyDrive/Licenta/models/weamyl-lstm_best_model_20220320193323.hdf5\n",
            "2057/2057 [==============================] - 1788s 869ms/step - loss: 86.5540 - mse: 86.7741 - mae: 4.2389\n",
            "Epoch 14/200\n",
            "2057/2057 [==============================] - ETA: 0s - loss: 86.1373 - mse: 86.3162 - mae: 4.2278\n",
            "Epoch 14: loss improved from 86.55401 to 86.13733, saving model to /content/drive/MyDrive/Licenta/models/weamyl-lstm_best_model_20220320193323.hdf5\n",
            "2057/2057 [==============================] - 1788s 869ms/step - loss: 86.1373 - mse: 86.3161 - mae: 4.2278\n",
            "Epoch 15/200\n",
            "2057/2057 [==============================] - ETA: 0s - loss: 85.7478 - mse: 85.9389 - mae: 4.2191\n",
            "Epoch 15: loss improved from 86.13733 to 85.74776, saving model to /content/drive/MyDrive/Licenta/models/weamyl-lstm_best_model_20220320193323.hdf5\n",
            "2057/2057 [==============================] - 1789s 870ms/step - loss: 85.7478 - mse: 85.9388 - mae: 4.2190\n",
            "Epoch 16/200\n",
            "2057/2057 [==============================] - ETA: 0s - loss: 85.3822 - mse: 85.5710 - mae: 4.2102\n",
            "Epoch 16: loss improved from 85.74776 to 85.38224, saving model to /content/drive/MyDrive/Licenta/models/weamyl-lstm_best_model_20220320193323.hdf5\n",
            "2057/2057 [==============================] - 1789s 870ms/step - loss: 85.3822 - mse: 85.5709 - mae: 4.2102\n",
            "Epoch 17/200\n",
            "2057/2057 [==============================] - ETA: 0s - loss: 85.0441 - mse: 85.2127 - mae: 4.2011\n",
            "Epoch 17: loss improved from 85.38224 to 85.04413, saving model to /content/drive/MyDrive/Licenta/models/weamyl-lstm_best_model_20220320193323.hdf5\n",
            "2057/2057 [==============================] - 1789s 870ms/step - loss: 85.0441 - mse: 85.2126 - mae: 4.2011\n",
            "Epoch 18/200\n",
            "2057/2057 [==============================] - ETA: 0s - loss: 84.7200 - mse: 84.8618 - mae: 4.1924\n",
            "Epoch 18: loss improved from 85.04413 to 84.72003, saving model to /content/drive/MyDrive/Licenta/models/weamyl-lstm_best_model_20220320193323.hdf5\n",
            "2057/2057 [==============================] - 1789s 870ms/step - loss: 84.7200 - mse: 84.8617 - mae: 4.1924\n",
            "Epoch 19/200\n",
            "2057/2057 [==============================] - ETA: 0s - loss: 84.4133 - mse: 84.5531 - mae: 4.1848\n",
            "Epoch 19: loss improved from 84.72003 to 84.41326, saving model to /content/drive/MyDrive/Licenta/models/weamyl-lstm_best_model_20220320193323.hdf5\n",
            "2057/2057 [==============================] - 1789s 870ms/step - loss: 84.4133 - mse: 84.5530 - mae: 4.1848\n",
            "Epoch 20/200\n",
            "2057/2057 [==============================] - ETA: 0s - loss: 84.1261 - mse: 84.2599 - mae: 4.1771\n",
            "Epoch 20: loss improved from 84.41326 to 84.12608, saving model to /content/drive/MyDrive/Licenta/models/weamyl-lstm_best_model_20220320193323.hdf5\n",
            "2057/2057 [==============================] - 1788s 869ms/step - loss: 84.1261 - mse: 84.2599 - mae: 4.1771\n",
            "Epoch 21/200\n",
            "2057/2057 [==============================] - ETA: 0s - loss: 83.8525 - mse: 83.9850 - mae: 4.1702\n",
            "Epoch 21: loss improved from 84.12608 to 83.85254, saving model to /content/drive/MyDrive/Licenta/models/weamyl-lstm_best_model_20220320193323.hdf5\n",
            "2057/2057 [==============================] - 1788s 869ms/step - loss: 83.8525 - mse: 83.9849 - mae: 4.1702\n",
            "Epoch 22/200\n",
            "2057/2057 [==============================] - ETA: 0s - loss: 83.5913 - mse: 83.7321 - mae: 4.1641\n",
            "Epoch 22: loss improved from 83.85254 to 83.59130, saving model to /content/drive/MyDrive/Licenta/models/weamyl-lstm_best_model_20220320193323.hdf5\n",
            "2057/2057 [==============================] - 1789s 870ms/step - loss: 83.5913 - mse: 83.7320 - mae: 4.1641\n",
            "Epoch 23/200\n",
            "2057/2057 [==============================] - ETA: 0s - loss: 83.3429 - mse: 83.4563 - mae: 4.1566\n",
            "Epoch 23: loss improved from 83.59130 to 83.34293, saving model to /content/drive/MyDrive/Licenta/models/weamyl-lstm_best_model_20220320193323.hdf5\n",
            "2057/2057 [==============================] - 1789s 870ms/step - loss: 83.3429 - mse: 83.4562 - mae: 4.1566\n",
            "Epoch 24/200\n",
            "2057/2057 [==============================] - ETA: 0s - loss: 83.1059 - mse: 83.2185 - mae: 4.1505\n",
            "Epoch 24: loss improved from 83.34293 to 83.10587, saving model to /content/drive/MyDrive/Licenta/models/weamyl-lstm_best_model_20220320193323.hdf5\n",
            "2057/2057 [==============================] - 1789s 870ms/step - loss: 83.1059 - mse: 83.2185 - mae: 4.1505\n",
            "Epoch 25/200\n",
            "2057/2057 [==============================] - ETA: 0s - loss: 82.8796 - mse: 82.9978 - mae: 4.1450\n",
            "Epoch 25: loss improved from 83.10587 to 82.87965, saving model to /content/drive/MyDrive/Licenta/models/weamyl-lstm_best_model_20220320193323.hdf5\n",
            "2057/2057 [==============================] - 1788s 869ms/step - loss: 82.8796 - mse: 82.9977 - mae: 4.1450\n",
            "Epoch 26/200\n",
            "2057/2057 [==============================] - ETA: 0s - loss: 82.6677 - mse: 82.7680 - mae: 4.1387\n",
            "Epoch 26: loss improved from 82.87965 to 82.66769, saving model to /content/drive/MyDrive/Licenta/models/weamyl-lstm_best_model_20220320193323.hdf5\n",
            "2057/2057 [==============================] - 1788s 869ms/step - loss: 82.6677 - mse: 82.7680 - mae: 4.1387\n",
            "Epoch 27/200\n",
            "2057/2057 [==============================] - ETA: 0s - loss: 82.4616 - mse: 82.5603 - mae: 4.1334\n",
            "Epoch 27: loss improved from 82.66769 to 82.46156, saving model to /content/drive/MyDrive/Licenta/models/weamyl-lstm_best_model_20220320193323.hdf5\n",
            "2057/2057 [==============================] - 1788s 869ms/step - loss: 82.4616 - mse: 82.5602 - mae: 4.1334\n",
            "Epoch 28/200\n",
            "2057/2057 [==============================] - ETA: 0s - loss: 82.2639 - mse: 82.3672 - mae: 4.1282\n",
            "Epoch 28: loss improved from 82.46156 to 82.26385, saving model to /content/drive/MyDrive/Licenta/models/weamyl-lstm_best_model_20220320193323.hdf5\n",
            "2057/2057 [==============================] - 1789s 870ms/step - loss: 82.2639 - mse: 82.3672 - mae: 4.1282\n",
            "Epoch 29/200\n",
            "2057/2057 [==============================] - ETA: 0s - loss: 82.0759 - mse: 82.1622 - mae: 4.1227\n",
            "Epoch 29: loss improved from 82.26385 to 82.07589, saving model to /content/drive/MyDrive/Licenta/models/weamyl-lstm_best_model_20220320193323.hdf5\n",
            "2057/2057 [==============================] - 1789s 869ms/step - loss: 82.0759 - mse: 82.1622 - mae: 4.1227\n",
            "Epoch 30/200\n",
            "  82/2057 [>.............................] - ETA: 28:34 - loss: 82.0650 - mse: 82.0703 - mae: 4.1202"
          ]
        }
      ],
      "source": [
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, callbacks=[checkpoint, csv_logger])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_60I5HmhNKi"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_va8xEbbhOe5"
      },
      "outputs": [],
      "source": [
        "# model = build_conv_lstm(x_train.shape)\n",
        "model = tf.keras.models.load_model('/content/drive/MyDrive/Licenta/models/ultimate_weamyl-lstm_best_model_20220320193323.hdf5', custom_objects={'CustomModel': CustomModel})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def nmae(y_true, y_pred):\n",
        "  mae = keras.losses.MeanAbsoluteError()(y_true, y_pred)\n",
        "  nmae = 100 * mae / (tf.reduce_max(y_true) - tf.reduce_min(y_true))\n",
        "  return nmae"
      ],
      "metadata": {
        "id": "4Cuf6Iu3kF2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-cHNB-FiSg3",
        "outputId": "3a859449-86b3-4e28-efaa-61b6298a05ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "72/72 [==============================] - 167s 2s/step - loss: 345723.6250 - mae: 4.3061 - mse: 88.0229 - nmae: 1.6881\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[345723.625, 4.306107044219971, 88.0229263305664, 1.6881005764007568]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "model.compile(loss=\"mae\", metrics=[\"mae\", \"mse\", nmae])\n",
        "\n",
        "model.evaluate(x_test, y_test, batch_size=8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRbJkRzplEa_"
      },
      "source": [
        "# Frame Prediction Visualizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZLNbXDYbmHy5"
      },
      "outputs": [],
      "source": [
        "all = []\n",
        "dx, dy = 30,30\n",
        "grid_color = [255,255,255]\n",
        "\n",
        "# max_preds = x_test.shape[0]\n",
        "max_preds = 25\n",
        "for img, truth in zip(x_test[:max_preds], y_test[:max_preds]):\n",
        "  pred = np.asarray(model(np.expand_dims(img, axis=0)), dtype=np.int32)\n",
        "  # pred = np.float32(model(np.expand_dims(img, axis=0)))\n",
        "  current_frames = []\n",
        "  for i in range(pred.shape[1]):\n",
        "    f = img[i, :, :, :]\n",
        "    f[:, ::dy, :] = grid_color\n",
        "    f[::dx, :, :] = grid_color \n",
        "    current_frames.append(np.int32(f))\n",
        "  p = pred[0, -1, :, :, :]\n",
        "  p[:, ::dy, :] = grid_color\n",
        "  p[::dx, :, :] = grid_color \n",
        "  current_frames.append(p)\n",
        "  t = truth[-1, :, :, :]\n",
        "  t[:, ::dy, :] = grid_color\n",
        "  t[::dx, :, :] = grid_color \n",
        "  current_frames.append(np.int32(t))\n",
        "  all.append(current_frames)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def img_similarity(x, y):\n",
        "  d = np.absolute(np.subtract(x, y))\n",
        "  return 100 - np.count_nonzero(d) * 100 / d.size"
      ],
      "metadata": {
        "id": "y-4OOVMJArmw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_similarity(all[0][5], all[0][8])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlDLPsgwBYcl",
        "outputId": "ac6ed5a8-ce5f-49ab-b6df-31d9009eb302"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27.52083333333333"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_747h1YSXbvJ"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "logging.getLogger('matplotlib').setLevel(logging.ERROR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vPW49LSfI8_i"
      },
      "outputs": [],
      "source": [
        "no_frame = len(all[0])\n",
        "frame_w = all[0][0].shape[1]\n",
        "frame_h = all[0][0].shape[0]\n",
        "px = 1/plt.rcParams['figure.dpi'] \n",
        "\n",
        "fig, axes = plt.subplots(len(all), no_frame, figsize=(no_frame * frame_w * 2 * px, len(all) * frame_h * 2 * px))\n",
        "for i in range(len(all)):\n",
        "  for j in range(len(axes[i])):\n",
        "    axes[i][j].imshow(np.int32(all[i][j]))\n",
        "    if j < no_frame - 2:\n",
        "      axes[i][j].set_title(f\"Frame {j + 1}\")\n",
        "    elif j == no_frame - 2:\n",
        "      axes[i][j].set_title(f\"Prediction\")\n",
        "    else:\n",
        "      axes[i][j].set_title(f\"Truth\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "CONV_LSTM.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}